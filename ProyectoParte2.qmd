---
title: "Trabajo Final"
format: pdf
editor: visual
---

```{r}
df <- read.csv("Criscbf/ANegocios/data/garments_worker_productivity.csv")
```

```{r}
library(tidyverse)
library(ggplot2)
library(dplyr)
library(GGally)
library(MLmetrics)
library(lmtest)
library(car)
library(gsubfn)
library(readr)
library(tidyverse)
library(DataExplorer)
library(rsample)
library(parsnip)
library(recipes)
library(workflows)
library(yardstick)
library(caret)
library(tensorflow)
library(keras)
library(reticulate)
library(nnet)
library(parallel)
library(doParallel)
library(MASS)
library(rpart)
library(rpart.plot)
library(corrplot)
library(skimr)
library(neuralnet)
library(nnet)
library(keras)
```

```{r}
skim(df)
```

```{r}
df <- df[complete.cases(df), ]
```

```{r}
df_iq <- aggregate(incentive ~ quarter, df, FUN = sum)
df_iq <- df_iq[order(df_iq$incentive, decreasing = T),]
ggplot(df_iq, aes(x= incentive, y = reorder(quarter, incentive))) +
  geom_col() +
  labs(x= "Incentive",
       y = "Quarter")
```

```{r}
df_aq <- aggregate(actual_productivity ~ quarter, df, FUN = sum)
df_aq <- df_aq[order(df_aq$actual_productivity, decreasing = T),]
ggplot(df_aq, aes(x= actual_productivity, y = reorder(quarter, actual_productivity))) +
  geom_col() +
  labs(x= "Actual productivity",
       y = "Quarter")
```

```{r}
df_atp <- aggregate(targeted_productivity ~ quarter, df, FUN = mean)
df_atp <- df_atp[order(df_atp$targeted_productivity, decreasing = T),]
ggplot(df_atp, aes(x= targeted_productivity, y = reorder(quarter,targeted_productivity))) +
  geom_col() +
  labs(x= "Targeted Productivity",
       y = "Quarter") +
  geom_point()
```

```{r}
colSums(is.na(df))
```

```{r}
plot_intro(df)
```

```{r}
plot_histogram(df)
```

```{r}
plot_intro(df)

```

```{r}
plot_correlation(df)

```

```{r}
plot_histogram(df)

```

```{r}
df[is.na(df)] <- 0
colSums(is.na(df))
```

```{r}
df <- df[, c("quarter", "team", "targeted_productivity","smv","wip","over_time","incentive","idle_time","idle_men","no_of_style_change","no_of_workers","actual_productivity")]

```

```{r}
df <- within(df, quarter[quarter == 'Quarter1'] <- 1)
df <- within(df, quarter[quarter == 'Quarter2'] <- 2)
df <- within(df, quarter[quarter == 'Quarter3'] <- 3)
df <- within(df, quarter[quarter == 'Quarter4'] <- 4)
df <- within(df, quarter[quarter == 'Quarter5'] <- 5)
df$team <- as.character(df$team)
```

```{r}
# Generate box plots of all numeric variables
new_df_num <- data.frame(df$targeted_productivity,
                           df$smv,
                           df$wip,
                           df$over_time,
                           df$incentive,
                           df$idle_time,
                           df$idle_men,
                           df$no_of_style_change,
                           df$no_of_workers,
                           df$actual_productivity)
col <- c("targeted_productivity", "standard_minute_value", 
         "work_in_progress", "over_time", "incentive", "idle_time", "idle_men", "no_of_style_change", 
         "no_of_workers", "actual_productivity")

colnames(new_df_num) <- col

ggplot(gather(new_df_num), aes(key,value)) +
  geom_boxplot(color="red", fill="yellow") +
  facet_wrap(~key, scales="free") +
  labs(title = "Box plots de la distribución de las variables no categoricas")
```

```{r}
split <- initial_split(df, prop = 0.8)
train_data <- training(split)
test_data <- testing(split)
```

```{r}
model_glm <- glm(actual_productivity~., data = train_data)
summary(model_glm)
probabilities <- model_glm %>% predict(test_data, type = "response")
predicted.classes <- ifelse(probabilities > 0.5, 1, 0)
logic_accurecy <- mean(predicted.classes==test_data$target)
logic_accurecy
print(paste0("Logistic Accurecy: ", logic_accurecy))
```

```{r}
library(rpart)
tree_fit = rpart(actual_productivity~., data = train_data)
summary(tree_fit)
rpart.plot(tree_fit)
```

```{r}
df$team <- as.numeric(df$team)
df$quarter <- as.numeric(df$quarter)
split <- initial_split(df, prop = 0.8)
train_data <- training(split)
test_data <- testing(split)
concrete_model <- neuralnet(actual_productivity~., data = train_data)
plot(concrete_model, rep="best")
```

```{r}
# Verificar si hay valores perdidos en train_data
missing_values <- is.na(train_data)

# Obtener el número total de valores perdidos
total_missing <- sum(missing_values)

# Imprimir el resultado
print(total_missing)
```

```{r}
concrete_model_2 <- neuralnet(
  actual_productivity ~ .,
  data = train_data,
  hidden = c(40),
  act.fct = "logistic",
  learningrate = 0.01,
  rep = 2
)
plot(concrete_model_2, rep = "best")
```

```{r}
resultados <- compute(concrete_model_2, test_data)
predicted_2 <- resultados$net.result
cor(predicted_2,test_data$actual_productivity)
```

```{r}
valores_actuales<-test_data$actual_productivity
MSE<-function(predicted_2,valores_actuales){
  n<-length(predicted_2)
  errores_cuadrados<-sum((predicted_2-valores_actuales)^2)
  return(errores_cuadrados/n)
}
MSE(predicted_2,valores_actuales)
```

```{r}
MAE<-function(predicted_2,valores_actuales){
  n<-length(predicted_2)
  errores_absolutos<-sum(abs(predicted_2-valores_actuales))
  return(errores_absolutos/n)
}
MAE(predicted_2,valores_actuales)
```

```{r}
MAPE<-function(predicted_2,valores_actuales){
  n<-length(predicted_2)
  errores_absolutos_porcentaje<-sum(abs((predicted_2-valores_actuales)/valores_actuales)*100)
  return(errores_absolutos_porcentaje/n)
}

MAPE(predicted_2,valores_actuales)
```

```{r}
print("MSE")
MSE(predicted_2,valores_actuales)

print("MSE")
MSE(predicted_2,valores_actuales)

print("MSE")
MSE(predicted_2,valores_actuales)
```

```{r}
concrete_model_1 <- keras_model_sequential() %>%
  layer_dense(units = 64, activation = "relu", input_shape = ncol(train_data) - 1) %>%
  layer_dense(units = 32, activation = "relu") %>%
  layer_dense(units = 1, activation = "sigmoid")

concrete_model_1 %>% compile(
  loss = "binary_crossentropy",
  optimizer = "adam",
  metrics = "accuracy"
)

history <- concrete_model_1 %>% fit(
  x = as.matrix(train_data[, -1]),
  y = as.numeric(train_data$actual_productivity) - 1,
  epochs = 50,
  batch_size = 16,
  verbose = 1
)

plot(history)
```
